{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import r2_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def _filter_low_counts(celltype_df, age_df, celltype_col, threshold):\n",
    "    print(\"Checking low count cell types...\")\n",
    "    \n",
    "    celltype_count = Counter(celltype_df[celltype_col])\n",
    "    for key in celltype_count:\n",
    "        if threshold == None:\n",
    "            unique_ages = np.unique(age_df)\n",
    "            num_groups = (len(unique_ages) + 1) * 100\n",
    "            if celltype_count[key] < num_groups:\n",
    "                print(key, \" has too low counts\")\n",
    "                celltype_df = celltype_df[celltype_df[celltype_col] != key]\n",
    "        else:\n",
    "            if celltype_count[key] < threshold:\n",
    "                print(key, \" has too low counts\")\n",
    "                celltype_df = celltype_df[celltype_df[celltype_col] != key]\n",
    "    return celltype_df\n",
    "\n",
    "def _get_skewed_count_info(adata, class_col, age_col, age_threshold):\n",
    "    print(\"Checking skewed count cell types...\")\n",
    "    \n",
    "    # Compute the fraction of cells for each age group within each cell ontology class\n",
    "    group_counts = adata.obs.groupby([class_col, age_col]).size()\n",
    "    total_counts = adata.obs.groupby([class_col]).size()\n",
    "    \n",
    "    # Calculate the fraction of each age group within each class\n",
    "    class_age_fraction = group_counts / total_counts\n",
    "    \n",
    "    # Find the cell classes to filter out based on age distribution\n",
    "    classes_to_filter = class_age_fraction[class_age_fraction > age_threshold].index.get_level_values(0).unique()\n",
    "    \n",
    "    return classes_to_filter\n",
    "    \n",
    "\n",
    "\n",
    "def read_and_filter_h5ad(filepath, class_col=\"celltype\", age_col=\"age\", filter_gender=True, gender=\"male\", age_threshold=0.8, count_threshold=None):\n",
    "    \"\"\"Parameters:\n",
    "    filepath: path to AnnData object\n",
    "        The Scanpy AnnData object containing single-cell data.\n",
    "    class_col: str, optional (default: 'celltype')\n",
    "        The column name in adata.obs representing the cell ontology class.\n",
    "    age_col: str, optional (default: 'age')\n",
    "        The column name in adata.obs representing the age of the cells.\n",
    "    filter_gender: boolen, optional (default: True)\n",
    "        Whether you would like to filter a gender out\n",
    "    gender: str, optional only if the filter_gender is True(default: \"male\")\n",
    "        Choose which gender to keep\n",
    "    age_threshold: float, optional (default: 0.8)\n",
    "        The threshold fraction for filtering based on age distribution. If one age group has more than this\n",
    "        fraction of cells in a class, the class will be filtered out.\n",
    "    count_threshold: int, optional (default: None(100))\n",
    "        Lower threshold for filtering cell types based on count.\n",
    " \n",
    "    Returns:\n",
    "    filtered_adata: AnnData object\n",
    "        The filtered AnnData object with specified cell ontology classes removed based on both criteria.\"\"\"\n",
    "    try:\n",
    "        adata = sc.read_h5ad(filepath)\n",
    "        \n",
    "        if filter_gender:\n",
    "             filtered_adata = adata[adata.obs[\"sex\"] == gender, :].copy()\n",
    "                \n",
    "        celltype_df = filtered_adata.obs[[class_col]].copy()\n",
    "        age_df = filtered_adata.obs[[age_col]].copy()\n",
    "        \n",
    "        # Apply the cell count threshold filtering\n",
    "        celltype_df = _filter_low_counts(celltype_df, age_df, class_col, count_threshold)\n",
    "    \n",
    "        # Create a filtered AnnData object based on cell count filtering\n",
    "        filtered_adata = filtered_adata[celltype_df.index].copy()\n",
    "        \n",
    "        # Identify the skewed classes to filter based on age distribution\n",
    "        classes_to_filter = _get_skewed_count_info(filtered_adata, class_col, age_col, age_threshold)\n",
    "        \n",
    "        if len(classes_to_filter):\n",
    "            print(classes_to_filter[0], \" has skewed cell counts\")\n",
    "            \n",
    "        # Further filter the AnnData object based on age distribution\n",
    "        final_filtered_adata = filtered_adata[~filtered_adata.obs[class_col].isin(classes_to_filter)].copy()\n",
    "        \n",
    "        return final_filtered_adata\n",
    "    except Exception as e:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 path: /Users/chanyue/Desktop/Pellegrini_Lab/Aging/Mouse_Tabula_Muris/tabula-muris-senis-facs-processed-official-annotations-Brain_combined.h5ad\n",
      "Checking low count cell types...\n",
      "macrophage  has too low counts\n",
      "interneuron  has too low counts\n",
      "neuron  has too low counts\n",
      "brain pericyte  has too low counts\n",
      "Bergmann glial cell  has too low counts\n",
      "neuroepithelial cell  has too low counts\n",
      "T cell  has too low counts\n",
      "mature NK T cell  has too low counts\n",
      "CD8-positive, alpha-beta T cell  has too low counts\n",
      "ependymal cell  has too low counts\n",
      "oligodendrocyte precursor cell  has too low counts\n",
      "neuronal stem cell  has too low counts\n",
      "medium spiny neuron  has too low counts\n",
      "Checking skewed count cell types...\n",
      "astrocyte  has skewed cell counts\n"
     ]
    }
   ],
   "source": [
    "# current_dir = Path.cwd()\n",
    "# print(f\"Current working directory: {current_dir}\")\n",
    "file1 = \"/Users/chanyue/Desktop/Pellegrini_Lab/Aging/Mouse_Tabula_Muris/tabula-muris-senis-facs-processed-official-annotations-Brain_combined.h5ad\"\n",
    "file2 = None\n",
    "print(f\"File 1 path: {file1}\")\n",
    "# assert file1.is_file(), f\"File not found: {file1}\"\n",
    "adata = read_and_filter_h5ad(file1, \"cell_ontology_class\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11151 × 22966\n",
       "    obs: 'FACS.selection', 'age', 'cell', 'cell_ontology_class', 'cell_ontology_id', 'free_annotation', 'method', 'mouse.id', 'sex', 'subtissue', 'tissue', 'n_genes', 'n_counts', 'louvain', 'leiden', 'batch'\n",
       "    var: 'n_cells', 'means-0', 'dispersions-0', 'dispersions_norm-0', 'highly_variable-0', 'means-1', 'dispersions-1', 'dispersions_norm-1', 'highly_variable-1'\n",
       "    obsm: 'X_pca', 'X_tsne', 'X_umap'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "A10_B002503_B009456_S10.mm10-plus-1-0-0     male\n",
       "A10_B002702_B009296_S154.mm10-plus-1-0-0    male\n",
       "A11_B002503_B009456_S11.mm10-plus-1-0-0     male\n",
       "A11_B002518_B009295_S71.mm10-plus-1-0-0     male\n",
       "A12_B002518_B009295_S72.mm10-plus-1-0-0     male\n",
       "                                            ... \n",
       "P8.MAA000932.3_11_M.1.1-1-1-1               male\n",
       "P9.MAA000560.3_10_M.1.1-1-1-1               male\n",
       "P9.MAA000564.3_10_M.1.1-1-1-1               male\n",
       "P9.MAA000932.3_11_M.1.1-1-1-1               male\n",
       "P9.MAA000935.3_8_M.1.1-1-1-1                male\n",
       "Name: sex, Length: 11151, dtype: category\n",
       "Categories (1, object): ['male']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs[\"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_genes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 11151 × 4667\n",
       "    obs: 'FACS.selection', 'age', 'cell', 'cell_ontology_class', 'cell_ontology_id', 'free_annotation', 'method', 'mouse.id', 'sex', 'subtissue', 'tissue', 'n_genes', 'n_counts', 'louvain', 'leiden', 'batch'\n",
       "    var: 'n_cells', 'means-0', 'dispersions-0', 'dispersions_norm-0', 'highly_variable-0', 'means-1', 'dispersions-1', 'dispersions_norm-1', 'highly_variable-1', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg'\n",
       "    obsm: 'X_pca', 'X_tsne', 'X_umap'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "A10_B002503_B009456_S10.mm10-plus-1-0-0      599\n",
      "A10_B002702_B009296_S154.mm10-plus-1-0-0    1547\n",
      "A11_B002503_B009456_S11.mm10-plus-1-0-0      622\n",
      "A11_B002518_B009295_S71.mm10-plus-1-0-0     2466\n",
      "A12_B002518_B009295_S72.mm10-plus-1-0-0     3324\n",
      "Name: n_genes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print out first 5 rows of the data\n",
    "print(adata.obs[\"n_genes\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = adata.X.toarray() if not isinstance(adata.X, np.ndarray) else adata.X\n",
    "\n",
    "# # Round values to nearest int and ensure non-negative\n",
    "# X = np.round(X).astype(int)\n",
    "# X[X < 0] = 0  # just in case\n",
    "\n",
    "# # Get gene names\n",
    "# genes = np.array(adata.var_names)\n",
    "\n",
    "# # Prepare the list of gene strings\n",
    "# gene_strings = []\n",
    "# for row in X:\n",
    "#     repeated_genes = np.repeat(genes, row)\n",
    "#     gene_string = \" \".join(repeated_genes)\n",
    "#     gene_strings.append(gene_string)\n",
    "\n",
    "# # Get relevant metadata\n",
    "# df_meta = adata.obs[['age', 'sex', 'cell_ontology_class', 'tissue']].copy()\n",
    "# df_meta.columns = ['age', 'gender', 'cell_ontology_class', 'tissue']\n",
    "\n",
    "# # Create final DataFrame\n",
    "# df_final = pd.DataFrame({\n",
    "#     'genes': gene_strings,\n",
    "#     'age': df_meta['age'].values,\n",
    "#     'gender': df_meta['gender'].values,\n",
    "#     'cell_ontology_class': df_meta['cell_ontology_class'].values,\n",
    "#     'tissue': df_meta['tissue'].values\n",
    "# })\n",
    "\n",
    "# # Set index as 0 to n-1\n",
    "# df_final.index = range(df_final.shape[0])\n",
    "\n",
    "# # Optional: Save to CSV\n",
    "# df_final.to_csv(\"processed_cells.csv\", index_label=\"index\")\n",
    "\n",
    "# # Return final DataFrame\n",
    "# df_final\n",
    "\n",
    "\n",
    "\n",
    "## too memory intensive \n",
    "## write to file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare output file\n",
    "# output_file = \"processed_cells_streamed.csv\"\n",
    "\n",
    "# # Get gene names\n",
    "# genes = np.array(adata.var_names)\n",
    "\n",
    "# # Get expression matrix (dense row-by-row)\n",
    "# X = adata.X\n",
    "\n",
    "# # Prepare metadata\n",
    "# ages = adata.obs[\"age\"].values\n",
    "# genders = adata.obs[\"sex\"].values\n",
    "# classes = adata.obs[\"cell_ontology_class\"].values\n",
    "# tissues = adata.obs[\"tissue\"].values\n",
    "\n",
    "# # Open file and write line-by-line\n",
    "# with open(output_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     # Write header\n",
    "#     writer.writerow([\"index\", \"genes\", \"age\", \"gender\", \"cell_ontology_class\", \"tissue\"])\n",
    "\n",
    "#     for i in range(adata.n_obs):\n",
    "#         # Get row i as dense array\n",
    "#         row = X[i].toarray().flatten() if not isinstance(X, np.ndarray) else X[i]\n",
    "        \n",
    "#         # Convert to int and clip negatives\n",
    "#         row = np.maximum(np.round(row).astype(int), 0)\n",
    "\n",
    "#         # Efficiently repeat gene names\n",
    "#         repeated_genes = np.repeat(genes, row)\n",
    "#         gene_string = \" \".join(repeated_genes)\n",
    "\n",
    "#         # Write row to file\n",
    "#         writer.writerow([\n",
    "#             i,\n",
    "#             gene_string,\n",
    "#             ages[i],\n",
    "#             genders[i],\n",
    "#             classes[i],\n",
    "#             tissues[i]\n",
    "#         ])\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'24m': 4554, '3m': 3942, '18m': 2655})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json, math, os, pathlib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ─── Pull data from AnnData ─────────────────────────────────────────────────────\n",
    "genes   = np.asarray(adata.var_names)\n",
    "X       = adata.X\n",
    "ages    = adata.obs[\"age\"].values\n",
    "genders = adata.obs[\"sex\"].values\n",
    "classes = adata.obs[\"cell_ontology_class\"].values\n",
    "tissues = adata.obs[\"tissue\"].values\n",
    "\n",
    "print(Counter(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── Split config ───────────────────────────────────────────────────────────────\n",
    "# N_SPLITS   = 11\n",
    "# SPLIT_SIZE = math.ceil(adata.n_obs / N_SPLITS)\n",
    "# OUT_DIR    = \"fine_tune_chunks\"\n",
    "# os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# INSTRUCTION = \"Predict the age of a single cell from gene expression and metadata.\"\n",
    "\n",
    "# def bag_of_words(counts_row: np.ndarray, gene_names: np.ndarray) -> str:\n",
    "#     \"\"\"Convert a vector of counts to space-separated tokens.\"\"\"\n",
    "#     counts_row = np.maximum(np.round(counts_row).astype(int), 0)\n",
    "#     return \" \".join(np.repeat(gene_names, counts_row))\n",
    "\n",
    "# # ─── Build chunk files in **Alpaca** format ─────────────────────────────────────\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "# for split_idx, (_, split_indices) in enumerate(skf.split(np.zeros(len(ages)), ages)):\n",
    "#     records = []\n",
    "#     for i in split_indices:\n",
    "#         row = X[i].toarray().ravel() if not isinstance(X, np.ndarray) else X[i]\n",
    "#         cell_input = (\n",
    "#             f\"Genes: {bag_of_words(row, genes)}\\n\"\n",
    "#             f\"Gender: {genders[i]}\\n\"\n",
    "#             f\"Class: {classes[i]}\\n\"\n",
    "#             f\"Tissue: {tissues[i]}\"\n",
    "#         )\n",
    "\n",
    "#         records.append({\n",
    "#             \"instruction\": INSTRUCTION,\n",
    "#             \"input\": cell_input,\n",
    "#             \"output\": str(ages[i])\n",
    "#         })\n",
    "#         break\n",
    "# #     fname = os.path.join(OUT_DIR, f\"cell_data_part_{split_idx+1}.json\")\n",
    "# #     with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "# #         json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# #     print(f\"Wrote {len(records):>5} samples → {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_1.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_2.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_3.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_4.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_5.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_6.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_7.json\n",
      "Wrote  1014 samples → fine_tune_chunks/cell_data_part_8.json\n",
      "Wrote  1013 samples → fine_tune_chunks/cell_data_part_9.json\n",
      "Wrote  1013 samples → fine_tune_chunks/cell_data_part_10.json\n",
      "Wrote  1013 samples → fine_tune_chunks/cell_data_part_11.json\n"
     ]
    }
   ],
   "source": [
    "# ─── Split config ───────────────────────────────────────────────────────────────\n",
    "N_SPLITS   = 11\n",
    "SPLIT_SIZE = math.ceil(adata.n_obs / N_SPLITS)\n",
    "OUT_DIR    = \"fine_tune_chunks\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "INSTRUCTION = \"Predict the age of a single cell from gene expression and metadata.\"\n",
    "\n",
    "def bag_of_words(counts_row: np.ndarray, gene_names: np.ndarray) -> str:\n",
    "    \"\"\"Convert a vector of counts to 'gene english(count)' tokens separated by space.\"\"\"\n",
    "    counts_row = np.maximum(np.round(counts_row).astype(int), 0)\n",
    "    tokens = [f\"{gene} {p.number_to_words(count)}\"\n",
    "        for gene, count in zip(gene_names, counts_row)\n",
    "        if count > 0]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ─── Build chunk files in **Alpaca** format ─────────────────────────────────────\n",
    "# check length \n",
    "lengths = []\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "for split_idx, (_, split_indices) in enumerate(skf.split(np.zeros(len(ages)), ages)):\n",
    "    records = []\n",
    "    for i in split_indices:\n",
    "        row = X[i].toarray().ravel() if not isinstance(X, np.ndarray) else X[i]\n",
    "        lengths.append(len(bag_of_words(row, genes)))\n",
    "        cell_input = (\n",
    "            f\"Genes: {bag_of_words(row, genes)}\\n\"\n",
    "            f\"Gender: {genders[i]}\\n\"\n",
    "            f\"Class: {classes[i]}\\n\"\n",
    "            f\"Tissue: {tissues[i]}\"\n",
    "        )\n",
    "    \n",
    "        records.append({\n",
    "            \"instruction\": INSTRUCTION,\n",
    "            \"input\": cell_input,\n",
    "            \"output\": str(ages[i])\n",
    "        })\n",
    "    fname = os.path.join(OUT_DIR, f\"cell_data_part_{split_idx+1}.json\")\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Wrote {len(records):>5} samples → {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12251, 1010)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths), min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
